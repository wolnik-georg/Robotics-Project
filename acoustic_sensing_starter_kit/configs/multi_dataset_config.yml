# Standard Pipeline with Multiple Datasets
# This runs the complete analysis pipeline on multiple combined datasets
# 
# NEW: All balanced datasets now include sweep.csv with position info for reconstruction

# Base data directory
base_data_dir: "data"

# Datasets to process (will be combined for training/testing)
# Using new balanced datasets with sweep.csv position info
datasets:
  # TRAINING: Workspaces 2 & 3 (all surfaces - cutout + pure contact + pure no-contact)
  
  # Workspace 2
  - "balanced_workspace_2_squares_cutout"
  - "balanced_workspace_2_pure_no_contact"
  - "balanced_workspace_2_pure_contact"
  
  # Workspace 3
  - "balanced_workspace_3_squares_cutout_v1"
  - "balanced_workspace_3_squares_cutout_v2"
  - "balanced_workspace_3_pure_contact"
  - "balanced_workspace_3_pure_no_contact"
  
# Optional: Specify datasets to use for validation (holdout)
# Leave empty [] to combine all datasets for train/test split
# These datasets have sweep.csv with position info for reconstruction
validation_datasets: [
  # VALIDATION: Workspace 1 (completely separate from training workspaces)
  "balanced_workspace_1_squares_cutout",
  "balanced_workspace_1_pure_no_contact",
  "balanced_workspace_1_pure_contact"
]

# Reconstruction Configuration
# After training, run surface reconstruction on validation datasets
reconstruction:
  enabled: true
  output_dir: "reconstruction_results"
  # Each validation dataset will be reconstructed separately using its sweep.csv

# Class Filtering Configuration
# NOTE: Already applied during balancing (--exclude-edge), but kept for pipeline compatibility
class_filtering:
  enabled: false  # Already filtered during balance_dataset.py
  classes_to_exclude_train: ["edge"]
  classes_to_exclude_validation: ["edge"]
  
  # Options:
  # 1. Exclude edge from both train & validation: Clean binary problem (contact vs no_contact)
  # 2. Exclude edge from train, include in validation: Test if model generalizes to edge cases
  # 3. Include edge in both: Full 3-class problem (more data needed)

# Domain Adaptation Configuration
# Test hypothesis: Does adding hold-out data to training improve generalization?
domain_adaptation:
  enabled: false  # Enable to mix hold-out data into training
  holdout_train_split: 0.3  # Fraction of hold-out data to add to training (0.0-1.0)
  # When enabled:
  #   - holdout_train_split (e.g., 0.3) goes to training
  #   - (1 - holdout_train_split) (e.g., 0.7) stays for validation
  # This tests if models memorized surface patterns vs learning general contact detection

# Feature Extraction Mode Configuration
# Choose between hand-crafted features, spectrograms, or both
# Now supports multiple modes for comparison
feature_extraction:
  modes:  # NEW: List of modes to test sequentially
    - "features"           # Hand-crafted features (65 dimensions)
    # - "spectrogram"        # Mel spectrograms (128×256 = 32,768 dimensions)
    # - "mfcc"              # MFCC features (13 × time_frames)
    # - "magnitude_spectrum" # Raw magnitude spectrum
    # - "power_spectrum"     # Power spectrum
    # - "chroma"             # Chroma features (12 bins)
    # - "both"               # Hand-crafted + full spectrograms
  
  # Default mode (for backward compatibility - will be overridden by modes list)
  mode: "features"  # Options: "features" | "spectrogram" | "mfcc" | "magnitude_spectrum" | "power_spectrum" | "chroma" | "both"
  
  # Spectrogram extraction parameters (used for spectrogram, mfcc, magnitude_spectrum, power_spectrum, chroma, both modes)
  # Optimized for CONTACT DETECTION: High-freq transients, short duration events
  spectrogram:
    n_fft: 512           # REDUCED: Shorter window for better time resolution (10.6ms @ 48kHz)
                         # Contact events are SHORT - need fine temporal detail
    hop_length: 128      # REDUCED: 75% overlap for smooth transitions (2.7ms hop)
                         # Catches fast transients that longer hops would miss
    n_mels: 80           # INCREASED: More frequency bands to capture contact harmonics
                         # Contact has rich frequency content across spectrum
    time_bins: 128       # INCREASED: More time detail to see impact onset
                         # Result: 80×128 = 10,240 features (2.5× larger BUT better for transients)
    fmin: 100            # INCREASED: Skip very low freq (robot motor noise)
    fmax: 20000          # Keep high freq where contact transients live
    use_log_scale: true  # dB scale emphasizes transients
    
    # MFCC-specific parameters
    n_mfcc: 13           # Number of MFCC coefficients
    
    # Chroma-specific parameters  
    n_chroma: 12         # Number of chroma bins
    
  # Per-sample normalization options
  # NOTE: Testing showed this HURTS performance (-5.8% validation accuracy)
  # The absolute magnitude of features carries discriminative information
  normalization:
    enabled: false       # DISABLED - hurt validation accuracy
    method: "zscore"     # Options: "zscore" (mean=0, std=1), "minmax" (0-1), "robust" (median/IQR), "l2" (unit norm)

# Analysis Experiments
experiments:
  data_processing:
    enabled: true
    apply_audio_smoothing: false
    use_workspace_invariant_features: true  # Enable workspace-invariant features for better generalization
    use_impulse_features: true  # NEW: Enable transfer function / impulse response features
    use_data_augmentation: true  # NEW: Enable data augmentation for training data
    augmentation_factor: 2  # How many augmented copies per original sample
    enhanced_augmentation: false  # DISABLED: Enhanced augmentation hurt performance (-2.9%)
    motion_artifact_removal:
      enabled: false

  dimensionality_reduction:
    enabled: true

  discrimination_analysis:
    enabled: true
    feature_selection:
      enabled: false  # DISABLED: Feature selection hurt performance (-1.0%) - all 80 features needed
      top_k_features: 50  # Number of top features to select (out of 80 total)
      method: "ensemble"  # Method: "ensemble" (RF+GB+XGB average ranks)
    
    # Confidence-Based Prediction Filtering
    # Filter out predictions with low confidence to reduce false positives
    confidence_filtering:
      enabled: true  # Set to true to enable confidence thresholding
      threshold: 0.9  # Minimum confidence (0.0-1.0) to accept prediction
      # If confidence < threshold:
      #   mode: "reject" → Mark as "uncertain" (excluded from metrics)
      #   mode: "default" → Use default class (e.g., "no_contact" as safe default)
      mode: "reject"  # Options: "reject" (exclude) or "default" (assign default class)
      default_class: "no_contact"  # Default class for low-confidence predictions (if mode="default")
      # Use case: In robotics, uncertain predictions → safer to assume no_contact than false contact

  saliency_analysis:
    enabled: false

  feature_ablation:
    enabled: false

  impulse_response:
    enabled: false

  frequency_band_ablation:
    enabled: false

  surface_reconstruction:
    enabled: false

# Output Configuration
output:
  base_dir: "training_for_reconstruction_v1"  # Train: W1&2&3 all surfaces, Validate: Hold-out dataset (Pattern B)

# Analysis Experiments (Standard Pipeline)
