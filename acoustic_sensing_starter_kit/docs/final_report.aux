\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wall2019morphological,wall2022passive,zoeller2020active}
\citation{zhang2025vibecheck}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {I-A}Research Questions}{1}{subsection.1.1}\protected@file@percent }
\citation{wall2019morphological}
\citation{wall2022passive}
\citation{zoeller2020active}
\citation{zhang2025vibecheck}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-B}Contributions}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}RELATED WORK}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Acoustic Sensing for Soft Robotics}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Robot Configuration Entanglement}{2}{subsection.2.2}\protected@file@percent }
\citation{wall2019morphological}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}Research Gaps and Our Approach}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}METHOD}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Experimental Setup}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Experimental setup showing the Franka Panda manipulator equipped with custom acoustic sensing end effector for contact detection and geometric reconstruction.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:setup}{{1}{3}{Experimental setup showing the Franka Panda manipulator equipped with custom acoustic sensing end effector for contact detection and geometric reconstruction.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Full experimental platform showing Franka Panda robot with acoustic finger positioned over test surface}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Acoustic finger mounting on robot gripper with integrated microphone and speaker}}}{3}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Close-up view of acoustic finger contact area (approximately 1\nobreakspace {}cm $\times $ 0.25\nobreakspace {}cm)}}}{3}{subfigure.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Test Objects and Workspace Configuration\relax }}{3}{table.caption.2}\protected@file@percent }
\newlabel{tab:objects}{{I}{3}{Test Objects and Workspace Configuration\relax }{table.caption.2}{}}
\citation{piczak2015environmental}
\citation{pedregosa2011scikit}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Single vs Multi-Sample Recording Protocol Validation (Binary Classification)\relax }}{4}{table.caption.3}\protected@file@percent }
\newlabel{tab:single_vs_multi}{{II}{4}{Single vs Multi-Sample Recording Protocol Validation (Binary Classification)\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Feature Engineering}{4}{subsection.3.2}\protected@file@percent }
\citation{pedregosa2011scikit}
\citation{pedregosa2011scikit}
\citation{mcfee2015librosa}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Hand-Crafted Features vs.\ Spectrograms Comparison (Rotation 1: Train WS1+WS3, Validate WS2)\relax }}{5}{table.caption.4}\protected@file@percent }
\newlabel{tab:feature_comparison}{{III}{5}{Hand-Crafted Features vs.\ Spectrograms Comparison (Rotation 1: Train WS1+WS3, Validate WS2)\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Hand-crafted acoustic feature architecture. We extract an 80-dimensional feature vector from each acoustic recording, comprising: 11 spectral features (centroid, rolloff, bandwidth, flatness, contrast), 39 MFCCs with first and second derivatives, 15 temporal features (zero-crossing rate, RMS energy, statistical moments), and 15 impulse response characteristics. This compact representation achieves 69.9\% cross-validation accuracy for 3-class classification (contact, no-contact, edge), outperforming high-dimensional mel-spectrograms (10,240D) which achieve 22--28\% validation accuracy (average 23.8\%).\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:features}{{2}{5}{Hand-crafted acoustic feature architecture. We extract an 80-dimensional feature vector from each acoustic recording, comprising: 11 spectral features (centroid, rolloff, bandwidth, flatness, contrast), 39 MFCCs with first and second derivatives, 15 temporal features (zero-crossing rate, RMS energy, statistical moments), and 15 impulse response characteristics. This compact representation achieves 69.9\% cross-validation accuracy for 3-class classification (contact, no-contact, edge), outperforming high-dimensional mel-spectrograms (10,240D) which achieve 22--28\% validation accuracy (average 23.8\%).\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Classification Pipeline}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Evaluation Strategy}{5}{subsection.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Classifier performance comparison: hand-crafted features vs.\ spectrograms on Rotation 1 validation (WS2). \textbf  {Left}: Hand-crafted features (80 dimensions) show moderate CV-validation gaps across all five classifiers, with Random Forest achieving best validation performance (33.9\%). \textbf  {Right}: Spectrograms (10,240 dimensions) exhibit severe overfitting with larger CV-validation gaps across all classifiers---Random Forest achieves 50.8\% CV but only 22.9\% validation (27.9pp gap). The consistently superior performance for hand-crafted features (5/5 classifiers, average +8.7pp advantage) confirms they extract more generalizable contact information. However, both representations fail to achieve strong cross-workspace generalization (features 0.98$\times $, spectrograms 0.71$\times $ over 33.3\% random baseline), revealing the dimensionality curse: 128$\times $ more parameters leads to worse performance.\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:feature_comparison_conf}{{3}{6}{Classifier performance comparison: hand-crafted features vs.\ spectrograms on Rotation 1 validation (WS2). \textbf {Left}: Hand-crafted features (80 dimensions) show moderate CV-validation gaps across all five classifiers, with Random Forest achieving best validation performance (33.9\%). \textbf {Right}: Spectrograms (10,240 dimensions) exhibit severe overfitting with larger CV-validation gaps across all classifiers---Random Forest achieves 50.8\% CV but only 22.9\% validation (27.9pp gap). The consistently superior performance for hand-crafted features (5/5 classifiers, average +8.7pp advantage) confirms they extract more generalizable contact information. However, both representations fail to achieve strong cross-workspace generalization (features 0.98$\times $, spectrograms 0.71$\times $ over 33.3\% random baseline), revealing the dimensionality curse: 128$\times $ more parameters leads to worse performance.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}EXPERIMENTAL RESULTS}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Proof of Concept: 3-Class Acoustic Contact Detection}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Position Generalization: Catastrophic Workspace-Dependent Failure}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Workspace rotation experimental strategy. Three rotations systematically evaluate position generalization: \textbf  {Rotation 1}: Train WS1+WS3 (7,290 samples), validate WS2 (1,338 samples). \textbf  {Rotation 2}: Train WS2+WS3 (7,290 samples), validate WS1 (1,362 samples). \textbf  {Rotation 3}: Train WS1+WS2 (8,028 samples), validate WS3 (1,215 samples). Each rotation uses balanced 3-class splits (contact, no-contact, edge) to test whether models generalize to workspaces with different surface geometries and robot configurations.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:experimental_setup}{{4}{7}{Workspace rotation experimental strategy. Three rotations systematically evaluate position generalization: \textbf {Rotation 1}: Train WS1+WS3 (7,290 samples), validate WS2 (1,338 samples). \textbf {Rotation 2}: Train WS2+WS3 (7,290 samples), validate WS1 (1,362 samples). \textbf {Rotation 3}: Train WS1+WS2 (8,028 samples), validate WS3 (1,215 samples). Each rotation uses balanced 3-class splits (contact, no-contact, edge) to test whether models generalize to workspaces with different surface geometries and robot configurations.\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Position Generalization Results (3 Workspace Rotations)\relax }}{7}{table.caption.10}\protected@file@percent }
\newlabel{tab:workspace_rotations}{{IV}{7}{Position Generalization Results (3 Workspace Rotations)\relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Object Generalization (3-Class): Train WS1+2+3 → Validate WS4 (Object D). Reproduced across 5 seeds (std=0.0\%).\relax }}{7}{table.caption.11}\protected@file@percent }
\newlabel{tab:object_gen}{{V}{7}{Object Generalization (3-Class): Train WS1+2+3 → Validate WS4 (Object D). Reproduced across 5 seeds (std=0.0\%).\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Object Generalization: Fundamental Limitation}{7}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Proof of concept: 3-class acoustic contact detection using 80/20 train/test split on combined workspace data (WS1+WS2+WS3). \textbf  {Top row}: Objects A (cutout - balanced across all 3 classes) and B (empty workspace - pure no-contact). \textbf  {Bottom}: Object C (full contact - contact and edge only). Each object shows ground truth (left) and predictions (right) with confusion matrix. The model achieves high accuracy across all objects (89.81\%, 99.82\%, 90.17\%, average 93.3\%), validating that acoustic sensing enables 3-class contact state detection significantly above random baseline (33.3\%) for within-workspace scenarios. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates contact state (contact=green, no-contact=red, edge=orange).\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:reconstruction_proof}{{5}{8}{Proof of concept: 3-class acoustic contact detection using 80/20 train/test split on combined workspace data (WS1+WS2+WS3). \textbf {Top row}: Objects A (cutout - balanced across all 3 classes) and B (empty workspace - pure no-contact). \textbf {Bottom}: Object C (full contact - contact and edge only). Each object shows ground truth (left) and predictions (right) with confusion matrix. The model achieves high accuracy across all objects (89.81\%, 99.82\%, 90.17\%, average 93.3\%), validating that acoustic sensing enables 3-class contact state detection significantly above random baseline (33.3\%) for within-workspace scenarios. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates contact state (contact=green, no-contact=red, edge=orange).\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Object Generalization (Binary): Train WS1+2+3 → Validate WS4 (Object D). All collapse to 50\% (std=0.0\%).\relax }}{9}{table.caption.12}\protected@file@percent }
\newlabel{tab:object_gen_binary}{{VI}{9}{Object Generalization (Binary): Train WS1+2+3 → Validate WS4 (Object D). All collapse to 50\% (std=0.0\%).\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces Position vs Object Generalization Comparison (3-Class)\relax }}{9}{table.caption.13}\protected@file@percent }
\newlabel{tab:position_vs_object}{{VII}{9}{Position vs Object Generalization Comparison (3-Class)\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {VIII}{\ignorespaces 3-Class vs Binary Classification Comparison\relax }}{10}{table.caption.15}\protected@file@percent }
\newlabel{tab:binary_comparison}{{VIII}{10}{3-Class vs Binary Classification Comparison\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Comparison: 3-Class vs Binary Classification}{10}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-E}Physics-Based Interpretation: Object and Workspace Specificity}{10}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}CONCLUSION}{11}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {V-A}Summary of Findings}{11}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {V-B}Contributions and Implications}{12}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {V-C}Future Directions}{12}{subsection.5.3}\protected@file@percent }
\citation{zoeller2020active}
\bibstyle{IEEEtranN}
\bibdata{project_scientific_report}
\bibcite{wall2019morphological}{{1}{2019}{{Wall}}{{}}}
\bibcite{wall2022passive}{{2}{2022}{{Wall et~al.}}{{Wall, Z\"{o}ller, and Brock}}}
\bibcite{zoeller2020active}{{3}{2020}{{Z\"{o}ller et~al.}}{{Z\"{o}ller, Wall, and Brock}}}
\bibcite{zhang2025vibecheck}{{4}{2025}{{Zhang et~al.}}{{Zhang, Kim, Tang, Liang, He, et~al.}}}
\bibcite{piczak2015environmental}{{5}{2015}{{Piczak}}{{}}}
\bibcite{pedregosa2011scikit}{{6}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.}}}
\bibcite{mcfee2015librosa}{{7}{2015}{{McFee et~al.}}{{McFee, Raffel, Liang, Ellis, McVicar, Battenberg, and Nieto}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-D}Limitations}{13}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Position generalization: 3-class reconstruction on Workspace 2 validation data (held out in Rotation 1). \textbf  {Layout}: Two objects in the top row (Objects A and B), with Object C centered in the bottom row. Each panel shows ground truth (left), predictions (middle), error map (top right), and 3×3 confusion matrix (bottom right). Object A (cutout, 32.04\% accuracy): balanced across all 3 classes (540 samples). Object B (empty workspace, 37.18\% accuracy): pure no-contact scenario (1,100 samples). Object C (full contact surface, 33.22\% accuracy): contact and edge classes only (590 samples). Trained on WS1+WS3, the model achieves 34.89\% weighted average accuracy across 2,230 samples---close to random chance (33.3\%) and demonstrating catastrophic performance degradation from the 69.1\% cross-validation accuracy, revealing severe workspace-dependent acoustic signatures. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates 3-class contact state (contact=green, no-contact=red, edge=orange).\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:reconstruction_position}{{6}{14}{Position generalization: 3-class reconstruction on Workspace 2 validation data (held out in Rotation 1). \textbf {Layout}: Two objects in the top row (Objects A and B), with Object C centered in the bottom row. Each panel shows ground truth (left), predictions (middle), error map (top right), and 3×3 confusion matrix (bottom right). Object A (cutout, 32.04\% accuracy): balanced across all 3 classes (540 samples). Object B (empty workspace, 37.18\% accuracy): pure no-contact scenario (1,100 samples). Object C (full contact surface, 33.22\% accuracy): contact and edge classes only (590 samples). Trained on WS1+WS3, the model achieves 34.89\% weighted average accuracy across 2,230 samples---close to random chance (33.3\%) and demonstrating catastrophic performance degradation from the 69.1\% cross-validation accuracy, revealing severe workspace-dependent acoustic signatures. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates 3-class contact state (contact=green, no-contact=red, edge=orange).\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Object generalization accuracy-coverage tradeoff on novel Object D (Workspace 4 holdout): GPU-MLP (Medium-HighReg) with and without confidence filtering. \textbf  {Left panel}: Without confidence filtering, spatial reconstruction achieves 33.03\% accuracy (random chance for 3-class problem) across all 2,280 spatial positions, demonstrating that the model cannot perform reliable full-surface reconstruction on novel object geometries. \textbf  {Right panel}: With confidence filtering (threshold $\geq $0.7), accuracy increases to 75.00\%, but only 4 out of 2,280 positions (0.2\% coverage) exceed the confidence threshold. Each panel displays ground truth (left), predictions (middle), error map (top right), and 3×3 confusion matrix (bottom right) for Object D. This reveals a fundamental accuracy-coverage tradeoff: the model can achieve high accuracy (75\%) on a tiny confident subset (0.2\% of positions) OR complete spatial coverage (100\%) with random-chance performance (33.03\%), but cannot achieve both simultaneously. The 75\% validation accuracy reported in Table\nobreakspace  {}\ref  {tab:object_gen} reflects performance only on this extremely filtered subset, not full spatial reconstruction capability. Heavy regularization (dropout 0.3, weight decay 0.01) enables the model to identify when it can make confident predictions, but fundamentally cannot generalize across the full spatial surface of novel object geometries. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates 3-class contact state (contact=green, no-contact=red, edge=orange).\relax }}{15}{figure.caption.14}\protected@file@percent }
\newlabel{fig:reconstruction_holdout}{{7}{15}{Object generalization accuracy-coverage tradeoff on novel Object D (Workspace 4 holdout): GPU-MLP (Medium-HighReg) with and without confidence filtering. \textbf {Left panel}: Without confidence filtering, spatial reconstruction achieves 33.03\% accuracy (random chance for 3-class problem) across all 2,280 spatial positions, demonstrating that the model cannot perform reliable full-surface reconstruction on novel object geometries. \textbf {Right panel}: With confidence filtering (threshold $\geq $0.7), accuracy increases to 75.00\%, but only 4 out of 2,280 positions (0.2\% coverage) exceed the confidence threshold. Each panel displays ground truth (left), predictions (middle), error map (top right), and 3×3 confusion matrix (bottom right) for Object D. This reveals a fundamental accuracy-coverage tradeoff: the model can achieve high accuracy (75\%) on a tiny confident subset (0.2\% of positions) OR complete spatial coverage (100\%) with random-chance performance (33.03\%), but cannot achieve both simultaneously. The 75\% validation accuracy reported in Table~\ref {tab:object_gen} reflects performance only on this extremely filtered subset, not full spatial reconstruction capability. Heavy regularization (dropout 0.3, weight decay 0.01) enables the model to identify when it can make confident predictions, but fundamentally cannot generalize across the full spatial surface of novel object geometries. All confusion matrices display 3×3 grids showing the complete 3-class problem (contact, edge, no-contact). Color indicates 3-class contact state (contact=green, no-contact=red, edge=orange).\relax }{figure.caption.14}{}}
\gdef \@abspage@last{15}
