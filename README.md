# Robotics-Project

> **Note:** The actual project lives in the [`acoustic_sensing_starter_kit/`](./acoustic_sensing_starter_kit/) subdirectory. Everything below is copied from there for convenience.

---

# Acoustic-Based Contact Detection for Robotic Manipulation

**End-to-End Experimental Pipeline for 3-Class Acoustic Contact Sensing**

This repository contains the complete implementation of acoustic sensing for contact detection and geometric reconstruction on rigid robotic manipulators, as described in the paper "Acoustic-Based Contact Detection and Geometric Reconstruction for Robotic Manipulation" (Wolnik, 2026).

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Findings](#key-findings)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Reproducing Main Results](#reproducing-main-results)
- [Pipeline Architecture](#pipeline-architecture)
- [Dataset Structure](#dataset-structure)
- [Configuration Files](#configuration-files)
- [Main Execution Scripts](#main-execution-scripts)
- [Source Code Structure](#source-code-structure)
- [Experimental Results](#experimental-results)
- [Figure Generation](#figure-generation)
- [Documentation](#documentation)
- [Advanced Usage](#advanced-usage)
- [Performance Summary](#performance-summary)
- [Troubleshooting](#troubleshooting)
- [Citation](#citation)

---

## ğŸ¯ Overview

This work investigates acoustic sensing as a contact detection modality for rigid robotic manipulators. We develop a complete pipeline from data collection through machine learning to 2D contact state mapping with explicit edge detection.

**Key Contributions:**
- First demonstration of **3-class acoustic contact detection** (contact, no-contact, edge) for rigid manipulators
- Systematic **generalization analysis**: position generalization (workspace rotations) and object generalization (novel geometries)
- Multi-seed validation proving **reproducibility** (5 independent seeds, std=0.0%)
- Physics-based **eigenfrequency analysis** explaining generalization failures and successes

**Experimental Platform:**
- Robot: Franka Emika Panda 7-DOF manipulator
- Sensor: Custom acoustic finger with contact microphone
- Objects: 4 wooden boards with different geometries (cutouts, raised shapes, empty)
- Workspaces: 4 different spatial configurations

---

## ğŸ”¬ Key Findings

### Proof of Concept (RQ1)
- **69.9% cross-validation accuracy** (2.10Ã— over random baseline)
- Validates feasibility for within-workspace scenarios
- 3-class outperforms binary when normalized (1.04Ã— vs 0.90Ã—)

### Position Generalization (RQ2)
- **Catastrophic workspace-dependent failure**: 23.3â€“55.7% validation range
- Average 34.5% (barely above 33.3% random baseline)
- Two rotations worse than random (0.70Ã— and 0.73Ã— normalized)
- **Workspace-specific training is mandatory**

### Object Generalization (RQ4)
- **Classifier-dependent results** validated across 5 seeds (std=0.0%)
- Heavily-regularized GPU-MLP: **75.0% validation** (dropout 0.3, weight decay 0.01)
- Unregularized models fail: 35.7â€“41.7%
- Binary classification collapses to **50% (pure random chance)**
- **Accuracy-coverage tradeoff**: 75% accuracy on only 0.2% of spatial positions

### 3-Class vs Binary (RQ3)
- Binary performs **worse than random guessing** (0.90Ã— normalized)
- 3-class achieves 1.04Ã— over random
- Edge samples contain **essential discriminative information**

---

## ğŸ”§ Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (optional, for GPU-MLP)

### Setup

1. **Clone the repository:**
```bash
git clone https://github.com/wolnik-georg/Robotics-Project.git
cd Robotics-Project/acoustic_sensing_starter_kit
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Verify installation:**
```bash
python run_modular_experiments.py --validate-only
```

### Key Dependencies

**Core Scientific Computing:**
- `numpy>=1.19.0`, `scipy>=1.5.0` - Numerical computing and scientific operations
- `pandas>=0.20.2` - Data manipulation and analysis

**Audio Processing:**
- `librosa>=0.9.0` - Audio feature extraction and spectral analysis
- `soundfile>=0.10.0` - Audio file I/O
- `pyaudio>=0.2.11` - Audio recording

**Machine Learning:**
- `scikit-learn>=0.20.0` - ML classifiers (Random Forest, SVM, LDA, MLP, K-NN)
- `xgboost>=1.5.0` - Gradient boosting classifier
- `imbalanced-learn>=0.8.0` - SMOTE and class balancing

**Deep Learning (GPU Acceleration - Optional):**
- `torch>=2.0.0`, `torchaudio>=2.0.0` - GPU-accelerated neural networks
- `cupy-cuda12x` - GPU-accelerated numpy operations

**Visualization:**
- `matplotlib>=3.3.0`, `seaborn>=0.11.0` - Plotting and visualization

**Hyperparameter Optimization:**
- `optuna>=3.0.0` - Automated hyperparameter tuning

**Configuration & Utilities:**
- `pyyaml>=5.4.0` - Configuration file parsing
- `pillow>=8.0.0`, `imageio>=2.9.0` - Image processing and I/O

---

## ğŸš€ Quick Start

### Complete Pipeline (One Command)

**Reproduce all main results** with a single command:

```bash
bash run_complete_pipeline.sh
```

This runs the entire pipeline end-to-end (~4-5 hours):
1. âœ… Dataset balancing
2. âœ… Position generalization (3 rotations)
3. âœ… Object generalization (5 seeds)
4. âœ… Figure generation

**For step-by-step execution**, see [Reproducing Main Results](#reproducing-main-results).

---

### Individual Components

#### 1. Dataset Balancing

Create perfectly balanced 3-class datasets (33/33/33 splits):

```bash
bash run_balance_datasets.sh
```

**Output:** `data/fully_balanced_datasets/rotation*_{train,val}/`

#### 2. Position Generalization (3 Workspace Rotations)

Run all 3 workspace rotations:

```bash
bash run_3class_rotations.sh
```

This executes:
- **Rotation 1**: Train WS1+WS3 â†’ Validate WS2
- **Rotation 2**: Train WS2+WS3 â†’ Validate WS1
- **Rotation 3**: Train WS1+WS2 â†’ Validate WS3

**Output:** `fully_balanced_rotation{1,2,3}_results/`

#### 3. Object Generalization (Multi-Seed Validation)

Run object generalization with 5 independent seeds:

```bash
python run_object_generalization_multiseed.py
```

Seeds tested: 42, 123, 456, 789, 1024

**Output:** `object_generalization_ws4_holdout_3class_seed_*/`

#### 4. Generate Figures

Create all reconstruction visualizations and ML analysis figures:

```bash
# Generate all 3 main reconstruction figures
python generate_comprehensive_reconstructions.py

# Generate ML analysis figures (feature architecture, experimental setup)
python generate_ml_analysis_figures.py
```

**Output:** 
- `comprehensive_3class_reconstruction/*.png`
- `ml_analysis_figures/*.png`

---

## ğŸ—ï¸ Pipeline Architecture

### End-to-End Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DATA COLLECTION                                              â”‚
â”‚    â””â”€ Raw datasets: data/collected_data_runs_*/                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. DATASET BALANCING                                            â”‚
â”‚    Script: create_fully_balanced_datasets.py                    â”‚
â”‚    Config: dataset_paths_config.yml                             â”‚
â”‚    Output: data/fully_balanced_datasets/rotation*_{train,val}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TRAINING & VALIDATION                                        â”‚
â”‚    Main Pipeline: run_modular_experiments.py                    â”‚
â”‚    Orchestrator: src/acoustic_sensing/experiments/orchestrator.pyâ”‚
â”‚                                                                  â”‚
â”‚    Position Generalization:                                     â”‚
â”‚    â””â”€ run_3class_rotations.sh                                  â”‚
â”‚       â”œâ”€ Rotation 1: configs/multi_dataset_config.yml          â”‚
â”‚       â”œâ”€ Rotation 2: configs/rotation_ws2_ws3_train_ws1_val.ymlâ”‚
â”‚       â””â”€ Rotation 3: configs/rotation_ws1_ws2_train_ws3_val.ymlâ”‚
â”‚                                                                  â”‚
â”‚    Object Generalization:                                       â”‚
â”‚    â””â”€ run_object_generalization_multiseed.py                   â”‚
â”‚       â””â”€ configs/object_generalization_3class_seed_*.yml       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FIGURE GENERATION                                            â”‚
â”‚    â”œâ”€ generate_comprehensive_reconstructions.py                â”‚
â”‚    â”‚  â””â”€ 3 main reconstruction figures                         â”‚
â”‚    â””â”€ generate_ml_analysis_figures.py                          â”‚
â”‚       â””â”€ Feature architecture, experimental setup              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. FINAL REPORT                                                 â”‚
â”‚    â””â”€ docs/final_report.tex (IEEE conference format)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Pipeline Component

**`run_modular_experiments.py`** is the **heart of the pipeline**:

```bash
python run_modular_experiments.py <config_file> [output_dir]

# Example:
python run_modular_experiments.py configs/multi_dataset_config.yml
```

**What it does:**
1. Loads YAML configuration
2. Initializes `ExperimentOrchestrator`
3. Loads data via `geometric_data_loader.py`
4. Extracts features (hand-crafted or spectrograms)
5. Trains classifiers via `multi_dataset_training.py`
6. Evaluates on validation data
7. Generates confusion matrices and metrics
8. (Optional) Performs 2D surface reconstruction

---

## ğŸ“ Dataset Structure

### Raw Data Collection

```
data/
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_1_squares_cutout_relabeled/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ audio_recordings/
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â””â”€â”€ sweep.csv (spatial positions)
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_1_pure_contact_relabeled/
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_1_pure_no_contact/
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_2_squares_cutout_relabeled/
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_2_pure_contact_relabeled/
â”œâ”€â”€ collected_data_runs_2026_01_15_workspace_2_pure_no_contact/
â”œâ”€â”€ collected_data_runs_2025_12_17_v2_workspace_3_squares_cutout_relabeled/
â”œâ”€â”€ collected_data_runs_2026_01_14_workspace_3_pure_contact_relabeled/
â”œâ”€â”€ collected_data_runs_2026_01_14_workspace_3_pure_no_contact/
â””â”€â”€ collected_data_runs_2026_01_27_hold_out_dataset_relabeled/  # WS4 Object D
```

**Dataset Types:**
- `*_squares_cutout_*`: Object A (wooden board with geometric cutouts)
- `*_pure_contact_*`: Object C (wooden board with raised shapes)
- `*_pure_no_contact`: Object B (empty workspace)
- `*_hold_out_*`: Object D (large square cutout, held-out for object generalization)

### Balanced 3-Class Datasets

Created by `create_fully_balanced_datasets.py`:

```
data/fully_balanced_datasets/
â”œâ”€â”€ rotation1_train/        # WS1 + WS3 combined, balanced
â”œâ”€â”€ rotation1_val/          # WS2, balanced
â”œâ”€â”€ rotation2_train/        # WS2 + WS3 combined
â”œâ”€â”€ rotation2_val/          # WS1
â”œâ”€â”€ rotation3_train/        # WS1 + WS2 combined
â”œâ”€â”€ rotation3_val/          # WS3
â””â”€â”€ holdout/                # WS4 Object D, balanced
```

**Each balanced dataset contains:**
- Perfect 33/33/33 class distribution (contact, no-contact, edge)
- `sweep.csv` with spatial position information for reconstruction
- `data/audio_recordings/` with balanced audio samples
- `metadata.json` with dataset information

---

## âš™ï¸ Configuration Files

### Main Pipeline Configurations

Located in `configs/`:

#### Position Generalization (Workspace Rotations)

| Config File | Training Data | Validation Data | Description |
|-------------|---------------|-----------------|-------------|
| `multi_dataset_config.yml` | WS1 + WS3 | WS2 | **Primary config** for Rotation 1 |
| `rotation_ws2_ws3_train_ws1_val.yml` | WS2 + WS3 | WS1 | Rotation 2 |
| `rotation_ws1_ws2_train_ws3_val.yml` | WS1 + WS2 | WS3 | Rotation 3 |

#### Binary Classification (for comparison)

| Config File | Mode |
|-------------|------|
| `rotation1_binary.yml` | Binary (exclude edge), Rotation 1 |
| `rotation2_binary.yml` | Binary, Rotation 2 |
| `rotation3_binary.yml` | Binary, Rotation 3 |

#### Object Generalization (Multi-Seed)

| Config File | Random Seed |
|-------------|-------------|
| `object_generalization_3class.yml` | Base config |
| `object_generalization_3class_seed_42.yml` | 42 |
| `object_generalization_3class_seed_123.yml` | 123 |
| `object_generalization_3class_seed_456.yml` | 456 |
| `object_generalization_3class_seed_789.yml` | 789 |
| `object_generalization_3class_seed_1024.yml` | 1024 |
| `object_generalization_binary.yml` | Binary mode |

### Configuration Structure

Example `multi_dataset_config.yml`:

```yaml
# Dataset paths
datasets:
  - "fully_balanced_datasets/rotation1_train"
  
validation_datasets:
  - "fully_balanced_datasets/rotation1_val"

# Class filtering (3-class vs binary)
class_filtering:
  enabled: false  # false = 3-class (contact, no_contact, edge)
  classes_to_exclude_train: ["edge"]
  classes_to_exclude_validation: ["edge"]

# Feature extraction
feature_extraction:
  modes:
    - "features"  # Hand-crafted features (80D)
    # - "spectrogram"  # Mel spectrograms (10,240D)
  
  spectrogram:
    n_fft: 512
    hop_length: 128
    n_mels: 80
    time_bins: 128

# Experiments to run
experiments:
  discrimination_analysis:
    enabled: true
    classifiers:
      - RandomForest
      - KNN
      - MLP
      - GPU_MLP
    cv_folds: 5
```

**Key Configuration Options:**

- `datasets`: Training dataset paths (can combine multiple workspaces)
- `validation_datasets`: Held-out validation datasets
- `class_filtering.enabled`: 
  - `false` = 3-class mode (contact, no_contact, edge)
  - `true` = binary mode (exclude edge samples)
- `feature_extraction.modes`: 
  - `"features"` = Hand-crafted features (80D: spectral, MFCCs, temporal, impulse)
  - `"spectrogram"` = Mel-spectrograms (10,240D)
- `experiments`: Which analyses to run (discrimination, reconstruction, etc.)

### Dataset Balancing Configuration

`dataset_paths_config.yml`:

```yaml
workspace_1:
  cutout: "data/collected_data_runs_2026_01_15_workspace_1_squares_cutout_relabeled"
  contact: "data/collected_data_runs_2026_01_15_workspace_1_pure_contact_relabeled"
  no_contact: "data/collected_data_runs_2026_01_15_workspace_1_pure_no_contact"

workspace_2:
  # ... similar structure

workspace_3:
  # ... similar structure

workspace_4:
  holdout: "data/collected_data_runs_2026_01_27_hold_out_dataset_relabeled"

output:
  directory: "data/fully_balanced_datasets"
```

---

## ğŸ¯ Main Execution Scripts

### Master Pipeline Script

| Script | Purpose | Usage |
|--------|---------|-------|
| `run_complete_pipeline.sh` | **Complete end-to-end pipeline** | `bash run_complete_pipeline.sh` |

**Recommended:** Use this script to reproduce all main results with one command.

Runs: Dataset balancing â†’ Position generalization â†’ Object generalization â†’ Figure generation

---

### Data Preparation

| Script | Purpose | Usage |
|--------|---------|-------|
| `create_fully_balanced_datasets.py` | Create balanced 3-class datasets | `python create_fully_balanced_datasets.py` |
| `run_balance_datasets.sh` | Shell wrapper for balancing | `bash run_balance_datasets.sh` |
| `analyze_dataset_balance.py` | Verify balance and distribution | `python analyze_dataset_balance.py` |

### Training & Validation

| Script | Purpose | Usage |
|--------|---------|-------|
| `run_modular_experiments.py` | **Main pipeline script** | `python run_modular_experiments.py <config> [output]` |
| `run_3class_rotations.sh` | Run all 3 rotations | `bash run_3class_rotations.sh` |
| `run_object_generalization_multiseed.py` | Multi-seed object generalization | `python run_object_generalization_multiseed.py` |
| `run_object_generalization.sh` | Single-seed wrapper | `bash run_object_generalization.sh` |
| `run_all_binary_experiments.sh` | Binary classification experiments | `bash run_all_binary_experiments.sh` |

### Figure Generation

| Script | Purpose | Output |
|--------|---------|--------|
| `generate_comprehensive_reconstructions.py` | All 3 main reconstruction figures | `comprehensive_3class_reconstruction/*.png` |
| `generate_ml_analysis_figures.py` | ML analysis figures | `ml_analysis_figures/*.png` |
| `generate_3class_rotation_figures.py` | Rotation comparison figures | Various |
| `create_combined_reconstruction_figures.py` | Combined panels | Various |
| `regenerate_all_figures_fully_balanced.py` | Regenerate all figures | Various |

### Analysis & Utilities

| Script | Purpose |
|--------|---------|
| `run_surface_reconstruction.py` | 2D spatial reconstruction from trained models |
| `analyze_dataset_balance.py` | Dataset balance verification |

---

## ğŸ“¦ Source Code Structure

### Main Package: `src/acoustic_sensing/`

```
src/acoustic_sensing/
â”œâ”€â”€ experiments/              # Experiment orchestration and execution
â”‚   â”œâ”€â”€ orchestrator.py       # Main experiment coordinator
â”‚   â”œâ”€â”€ multi_dataset_training.py  # Multi-dataset training logic
â”‚   â”œâ”€â”€ discrimination_analysis.py # ML classifier training/evaluation
â”‚   â”œâ”€â”€ surface_reconstruction.py  # 2D spatial reconstruction
â”‚   â”œâ”€â”€ data_processing.py    # Data loading and preprocessing
â”‚   â”œâ”€â”€ gpu_classifiers.py    # GPU-accelerated MLP implementations
â”‚   â””â”€â”€ base_experiment.py    # Base class for all experiments
â”‚
â”œâ”€â”€ features/                 # Feature extraction
â”‚   â””â”€â”€ (Feature extraction modules)
â”‚
â”œâ”€â”€ models/                   # Data loading and reconstruction
â”‚   â”œâ”€â”€ geometric_data_loader.py   # Load data with spatial positions
â”‚   â”œâ”€â”€ geometric_reconstruction.py # Reconstruct from predictions
â”‚   â””â”€â”€ training.py           # Training utilities
â”‚
â”œâ”€â”€ analysis/                 # Analysis modules
â”‚   â”œâ”€â”€ discrimination_analysis.py # Classifier comparison and metrics
â”‚   â”œâ”€â”€ batch_analysis.py     # Batch processing utilities
â”‚   â””â”€â”€ dimensionality_analysis.py # PCA, t-SNE analysis
â”‚
â”œâ”€â”€ visualization/            # Plotting and figure generation
â”‚   â””â”€â”€ (Visualization utilities)
â”‚
â””â”€â”€ core/                     # Core utilities
    â””â”€â”€ (Core functionality)
```

---

## ğŸ“Š Experimental Results

### Results Directory Structure

```
acoustic_sensing_starter_kit/
â”œâ”€â”€ fully_balanced_rotation1_results/
â”œâ”€â”€ fully_balanced_rotation2_results/
â”œâ”€â”€ fully_balanced_rotation3_results/
â”œâ”€â”€ object_generalization_ws4_holdout_3class_seed_42/
â”œâ”€â”€ object_generalization_ws4_holdout_3class_seed_123/
â”œâ”€â”€ object_generalization_ws4_holdout_3class_seed_456/
â”œâ”€â”€ object_generalization_ws4_holdout_3class_seed_789/
â””â”€â”€ object_generalization_ws4_holdout_3class_seed_1024/
```

---

## ğŸ¨ Figure Generation

Generated by `generate_comprehensive_reconstructions.py` â†’ `comprehensive_3class_reconstruction/`:

1. **`proof_of_concept_reconstruction_combined.pdf`** â€” 80/20 split, ~93% average accuracy
2. **`test/`** â€” Position generalization test data reconstructions
3. **`validation/`** â€” Position generalization validation reconstructions
4. **`holdout/`** â€” Object generalization reconstruction (33% = random chance)

---

## ğŸ“š Documentation

- **`DATA_COLLECTION_PROTOCOL.md`** â€” Data collection methodology
- **`PIPELINE_GUIDE.md`** â€” Pipeline usage guide
- **`PHYSICS_FIRST_PRINCIPLES_INTERPRETATION.md`** â€” Eigenfrequency analysis
- **`RESEARCH_FINDINGS_ACOUSTIC_CONTACT_DETECTION.md`** â€” Comprehensive findings
- **`docs/final_report_condensed.tex`** â€” IEEE conference format paper

---

## ğŸ”¬ Reproducing Main Results

```bash
# Full pipeline (recommended)
cd acoustic_sensing_starter_kit/
bash run_complete_pipeline.sh
```

See [`acoustic_sensing_starter_kit/README.md`](./acoustic_sensing_starter_kit/README.md) for detailed step-by-step instructions.

---

## ğŸ“ˆ Performance Summary

| Experiment | Val Accuracy | Random Baseline | Normalized |
|------------|-------------|-----------------|------------|
| Proof of Concept (CV) | 69.9% | 33.3% | 2.10Ã— |
| Position Gen (avg) | 34.5% | 33.3% | 1.04Ã— |
| Object Gen (RF) | 41.7% | 33.3% | 1.25Ã— |
| Object Gen (GPU-MLP HighReg) | 75.0% | 33.3% | 2.25Ã— |
| Binary Classification | 45.1% | 50.0% | 0.90Ã— âš ï¸ |

---

## ğŸ“– Citation

```bibtex
@inproceedings{wolnik2026acoustic,
  title={Acoustic-Based Contact Detection and Geometric Reconstruction for Robotic Manipulation},
  author={Wolnik, Georg},
  booktitle={Proceedings of [Conference Name]},
  year={2026},
  organization={Technische Universit{\"a}t Berlin}
}
```

---

**Author:** Georg Wolnik â€” Robotics and Biology Laboratory, TU Berlin  
**Last Updated:** February 25, 2026
